{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used GPT-4-o1-preview to generate an ontology. first prompted it to generate tasks (via chatgpt interface):\n",
    "\n",
    "```\n",
    "you are an expert in psychological research.  Researchers in the field of psychology study specific \n",
    "psychological constructs, which are the building blocks of the mind, such as \n",
    "memory, attention, theory of mind, and so on.  To study them, researchers use \n",
    "experimental tasks or surveys, which are meant to measure behavior related to the \n",
    "constructs.  In many cases psychological tasks have several different experimental\n",
    "conditions, which are meant to manipulate the construct in different ways.  These are \n",
    "commonly compared to one another in order to measure the effect of the manipulation; we \n",
    "refer to these comparisons as contrasts.\n",
    "\n",
    "your job is to generate a list of all of the psychological tasks and surveys used by researchers in this field.  Please be as specific and exhaustive as possible. \n",
    "\n",
    "you should return these as a JSON list, with no additional text.\n",
    "```\n",
    "\n",
    "This identified a list of 144 tasks.  These were then used to generate descriptions using the following prompt:\n",
    "\n",
    "```\n",
    "for each of these tasks, please generate:\n",
    "\n",
    "1) a brief description of the task\n",
    "2) a list of the psychological constructs that the task is used to assess\n",
    "3) a small number of references for each task\n",
    "\n",
    "Please return these as a dictionary of sub-dictionaries, with the task names as keys and with the elements 'description', 'constructs', and 'references' within each sub-dictionary\n",
    "```\n",
    "\n",
    "Results from this were stored in [gpt4_task_ontology.json]()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/poldrack/Dropbox/data/ontology-learner/data\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from ontology_learner.gpt4_batch_utils import get_batch_results, save_batch_results\n",
    "from llm_query.chat_client import ChatClientFactory\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "datadir = Path(os.getenv('DATADIR'))\n",
    "print(datadir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n"
     ]
    }
   ],
   "source": [
    "with open(datadir / 'gpt4/gpt4_task_ontology.json') as f:\n",
    "    ontology = json.load(f)\n",
    "\n",
    "print(len(ontology))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we extract all of the constructs for further annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186\n"
     ]
    }
   ],
   "source": [
    "constructs = {}\n",
    "\n",
    "for taskname, taskdict in ontology.items():\n",
    "    for construct in taskdict['constructs']:\n",
    "        if construct not in constructs:\n",
    "            constructs[construct] = []\n",
    "        constructs[construct].append(taskname)\n",
    "\n",
    "print(len(constructs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create json list of constructs\n",
    "\n",
    "with open(datadir / 'gpt4/gpt4_construct_list.json', 'w') as f:\n",
    "    json.dump(list(constructs.keys()), f, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This list was then fed into GPT-4-o1-preview with the following prompt:\n",
    "\n",
    "```\n",
    "The following is a list of psychological constructs identified above.  These represent only a fraction of all of the constructs that are studied in the field.  please use your expert knowledge of psychology to expand this list to contain a wider selection of the constructs studied within the field.  Please return your result as a json list.\n",
    "```\n",
    "\n",
    "the result was saved to [gpt4_expanded_construct_list.json]()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "866\n",
      "807\n"
     ]
    }
   ],
   "source": [
    "with open(datadir / 'gpt4/gpt4_expanded_construct_list.json') as f:\n",
    "    expanded_constructs = json.load(f)\n",
    "\n",
    "print(len(expanded_constructs))\n",
    "expanded_constructs = list(set(expanded_constructs))\n",
    "print(len(expanded_constructs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried to further expand these but the chatgpt interface wouldn't do it due to the length of the list, so we then move to the API.  We also switch to GPT-4o due to cost of o1-preview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_construct_prompt(construct):\n",
    "    prompt = f\"\"\"\n",
    "# CONTEXT #\n",
    "Researchers in the field of cognitive neuroscience and psychology study specific \n",
    "psychological constructs, which are the building blocks of the mind, such as \n",
    "memory, attention, theory of mind, and so on.  \n",
    "\n",
    "# OBJECTIVE #\n",
    "Your job is to analyze a specific construct: {construct}.\n",
    "\n",
    "- You should first determine whether it is truly a psychological construct, or whether it is some \n",
    "other kind of thing.  For example, \"working memory\" is a psychological construct, \n",
    "but \"n-back task\" is not (it is a task, not a construct).  Include a 'type' key in your response with the value 'construct' if it is \n",
    "truly a psychological construct or 'other' if it is not.\n",
    "\n",
    "If it is a psychological construct, please do the following:\n",
    "- provide a short description of the construct.\n",
    "- provide a short list of widely cited publications that describe the construct. Include a \n",
    "'references' key in your response with a list of the references.\n",
    "- provide a list of commonly used tasks or surveys that measure the construct.  Include a 'tasks' key in your response with a list of the tasks.\n",
    "- Provide a list of other constructs that are related to this construct.  Include a 'related_constructs' key in your response with a list of the related constructs.\n",
    "Be as specific as possible, using names that are as specific as possible.\n",
    "\n",
    "# RESPONSE #\n",
    "Please return the results in JSON format.  Use the following keys:\n",
    "- type: 'construct', or 'other'\n",
    "- description: a short description of the construct\n",
    "- references: a list of references that use the construct\n",
    "- tasks: a list of tasks used to measure the construct\n",
    "- related_constructs: a list of other constructs that are related to this construct\n",
    "Respond only with JSON, without any additional text or description.\n",
    "\"\"\"\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create batch submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ.get(\"OPENAI\")\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "system_msg = \"\"\"\n",
    "    You are an expert in psychology and neuroscience.\n",
    "    You should be as specific and as comprehensive as possible in your responses.\n",
    "    Your response should be a JSON object with no additional text.  \n",
    "    \"\"\"\n",
    "\n",
    "# wanted to use 01-preview but it's too expensive so we fall back to GPT-4o\n",
    "model = 'gpt-4o'\n",
    "client = ChatClientFactory.create_client(\"openai\", api_key, \n",
    "                                            system_msg=system_msg,\n",
    "                                            model=model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batchfile = datadir / 'gpt4/gpt4_construct_expansion_batch.jsonl'\n",
    "\n",
    "if batchfile.exists():\n",
    "    batchfile.unlink()\n",
    "\n",
    "for construct in expanded_constructs:\n",
    "\n",
    "    prompt = get_construct_prompt(construct)\n",
    "    kwargs = {'model': model,  'messages': [{\"role\": \"user\", \"content\": prompt}]}\n",
    "    try:\n",
    "        batch_request = client.create_batch_request(construct, prompt)\n",
    "    except Exception as e:\n",
    "        print(f'error processing {pmcid}: {e}')\n",
    "        continue\n",
    "\n",
    "    with open(batchfile, 'a') as f:\n",
    "        f.write(json.dumps(batch_request) + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run batch request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_client = OpenAI(api_key=api_key)\n",
    "\n",
    "batch_input_file = batch_client.files.create(file=open(batchfile, \"rb\"),\n",
    "                                        purpose=\"batch\")\n",
    "\n",
    "batch_input_file_id = batch_input_file.id\n",
    "\n",
    "batch_metadata = batch_client.batches.create(\n",
    "    input_file_id=batch_input_file_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "        \"description\": \"construct annotation\"\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(id='batch_674e46adb93c8190beb9deb06e953f58', completion_window='24h', created_at=1733183149, endpoint='/v1/chat/completions', input_file_id='file-BxE44oJVDJv7AYusX95EL6', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='duplicate_custom_id', line=190, message='The custom_id for this request is a duplicate of another request. The custom_id parameter must be unique for each request in a batch.', param='custom_id'), BatchError(code='duplicate_custom_id', line=246, message='The custom_id for this request is a duplicate of another request. The custom_id parameter must be unique for each request in a batch.', param='custom_id'), BatchError(code='duplicate_custom_id', line=300, message='The custom_id for this request is a duplicate of another request. The custom_id parameter must be unique for each request in a batch.', param='custom_id'), BatchError(code='duplicate_custom_id', line=301, message='The custom_id for this request is a duplicate of another request. The custom_id parameter must be unique for each request in a batch.', param='custom_id'), BatchError(code='duplicate_custom_id', line=305, message='The custom_id for this request is a duplicate of another request. The custom_id parameter must be unique for each request in a batch.', param='custom_id'), BatchError(code='duplicate_custom_id', line=310, message='The custom_id for this request is a duplicate of another request. The custom_id parameter must be unique for each request in a batch.', param='custom_id'), BatchError(code='duplicate_custom_id', line=313, message='The custom_id for this request is a duplicate of another request. The custom_id parameter must be unique for each request in a batch.', param='custom_id'), BatchError(code='duplicate_custom_id', line=327, message='The custom_id for this request is a duplicate of another request. The custom_id parameter must be unique for each request in a batch.', param='custom_id'), BatchError(code='duplicate_custom_id', line=400, message='The custom_id for this request is a duplicate of another request. The custom_id parameter must be unique for each request in a batch.', param='custom_id'), BatchError(code='duplicate_custom_id', line=434, message='The custom_id for this request is a duplicate of another request. The custom_id parameter must be unique for each request in a batch.', param='custom_id'), BatchError(code='duplicate_custom_id', line=450, message='The custom_id for this request is a duplicate of another request. The custom_id parameter must be unique for each request in a batch.', param='custom_id'), BatchError(code='duplicate_custom_id', line=453, message='The custom_id for this request is a duplicate of another request. The custom_id parameter must be unique for each request in a batch.', param='custom_id'), BatchError(code='duplicate_custom_id', line=455, message='The custom_id for this request is a duplicate of another request. The custom_id parameter must be unique for each request in a batch.', param='custom_id'), BatchError(code='duplicate_custom_id', line=486, message='The custom_id for this request is a duplicate of another request. The custom_id parameter must be unique for each request in a batch.', param='custom_id'), BatchError(code='duplicate_custom_id', line=555, message='The custom_id for this request is a duplicate of another request. The custom_id parameter must be unique for each request in a batch.', param='custom_id'), BatchError(code='duplicate_custom_id', line=559, message='The custom_id for this request is a duplicate of another request. The custom_id parameter must be unique for each request in a batch.', param='custom_id'), BatchError(code='duplicate_custom_id', line=601, message='The custom_id for this request is a duplicate of another request. The custom_id parameter must be unique for each request in a batch.', param='custom_id'), BatchError(code='duplicate_custom_id', line=623, message='The custom_id for this request is a duplicate of another request. The custom_id parameter must be unique for each request in a batch.', param='custom_id'), BatchError(code='duplicate_custom_id', line=680, message='The custom_id for this request is a duplicate of another request. The custom_id parameter must be unique for each request in a batch.', param='custom_id'), BatchError(code='duplicate_custom_id', line=697, message='The custom_id for this request is a duplicate of another request. The custom_id parameter must be unique for each request in a batch.', param='custom_id')], object='list'), expired_at=None, expires_at=1733269549, failed_at=1733183150, finalizing_at=None, in_progress_at=None, metadata={'description': 'construct annotation'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n"
     ]
    }
   ],
   "source": [
    "print(batch_client.batches.retrieve(batch_metadata.id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "finalizing\n",
      "finalizing\n",
      "completed\n"
     ]
    }
   ],
   "source": [
    "print(batch_client.batches.retrieve(batch_metadata.id).status)\n",
    "import time\n",
    "while batch_client.batches.retrieve(batch_metadata.id).status != 'completed':\n",
    "    time.sleep(60)\n",
    "    print(batch_client.batches.retrieve(batch_metadata.id).status)\n",
    "# os.system('say \"your program has finished\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from gpt4_batch_utils import get_batch_results, save_batch_results\n",
    "batch_results = get_batch_results(batch_client, batch_metadata.id)\n",
    "outdir = datadir / 'gpt4/construct_refinement_results'\n",
    "outdir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "outfile = save_batch_results(batch_results, batch_metadata.id, outdir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
